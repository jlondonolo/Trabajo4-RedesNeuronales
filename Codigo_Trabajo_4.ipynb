{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generador de Contenido Educativo con LLM"
      ],
      "metadata": {
        "id": "JXTur3c2r0rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y pandoc texlive-xetex\n",
        "!pip install markdown2 pypandoc google-generativeai\n",
        "!pip install pdfplumber\n",
        "!pip install pytesseract pdf2image\n",
        "!pip install DOCX PyPDF2\n",
        "!pip install pypandoc python-docx pdfplumber pdf2image pytesseract\n",
        "!apt-get update\n",
        "!apt-get install -y pandoc texlive-xetex\n",
        "!pip install markdown2 pypandoc google-generativeai"
      ],
      "metadata": {
        "id": "miGP-pONXDBZ",
        "outputId": "821d708e-1519-4fdf-84e6-22ef5d23f3bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.83)] [Waiting for headers] [Connecting to r2u.sta\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected to r2u.stat\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r0% [3 InRelease 12.7 kB/128 kB 10%] [Connecting to security.ubuntu.com (185.125.190.83)] [Connected \r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecte\r                                                                                                    \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcont\r                                                                                                    \rGet:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,988 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 4,905 kB in 1s (5,840 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (2.9.2.1-3ubuntu2).\n",
            "texlive-xetex is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.11/dist-packages (2.5.3)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.11/dist-packages (1.15)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Requirement already satisfied: DOCX in /usr/local/lib/python3.11/dist-packages (0.2.4)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from DOCX) (5.3.1)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.11/dist-packages (from DOCX) (11.1.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.11/dist-packages (1.15)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pandoc is already the newest version (2.9.2.1-3ubuntu2).\n",
            "texlive-xetex is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: markdown2 in /usr/local/lib/python3.11/dist-packages (2.5.3)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.11/dist-packages (1.15)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Course content\n",
        "course_content = \"\"\"\n",
        "Contenido del curso Cálculo diferencial.\n",
        "Unidades:\n",
        "1. Introducción a la derivada\n",
        "2. Derivada de la función compuesta\n",
        "3. Aplicaciones de la derivada en problemas de razón de cambio\n",
        "\n",
        "Autor: Juan David Ospina Arango\n",
        "Profesor Asociado\n",
        "Departamento de Ciencias de la Computación y de la Decisión\n",
        "Universidad Nacional de Colombia\n",
        "\"\"\"\n",
        "\n",
        "# Your API key\n",
        "api_key = \"Mi_API\"  # Replace with your real Google API key\n",
        "\n",
        "# Execute the code - everything in one cell\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import google.generativeai as genai\n",
        "import markdown2\n",
        "import pypandoc\n",
        "\n",
        "# Configure basic logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(\"eduagent\")\n",
        "\n",
        "class GeminiClient:\n",
        "    \"\"\"Client to interact with Google Gemini API for content generation.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key, model=\"gemini-2.0-flash-001\", temperature=0.4, max_tokens=4000,\n",
        "                 cache_dir=\"./data/cache/gemini\", use_cache=True, max_retries=3):\n",
        "        self.api_key = api_key\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "        self.max_retries = max_retries\n",
        "        self.use_cache = use_cache\n",
        "        self.total_tokens_used = 0\n",
        "        self.total_requests = 0\n",
        "        self.total_cost = 0.0\n",
        "        self.request_history = []\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.generation_config = {\n",
        "            \"temperature\": temperature,\n",
        "            \"max_output_tokens\": max_tokens,\n",
        "            \"top_p\": 0.9,\n",
        "            \"top_k\": 40\n",
        "        }\n",
        "\n",
        "    def _calculate_cost(self, prompt_tokens, completion_tokens):\n",
        "        model_prices = {\n",
        "            \"gemini-2.0-flash-001\": {\"prompt\": 0.0001, \"completion\": 0.0002},\n",
        "            \"gemini-1.5-flash-001\": {\"prompt\": 0.0001, \"completion\": 0.0002},\n",
        "            \"gemini-1.5-pro-001\": {\"prompt\": 0.0005, \"completion\": 0.0015}\n",
        "        }\n",
        "        price_info = model_prices.get(self.model, {\"prompt\": 0.0001, \"completion\": 0.0002})\n",
        "        prompt_cost = (prompt_tokens / 1000) * price_info[\"prompt\"]\n",
        "        completion_cost = (completion_tokens / 1000) * price_info[\"completion\"]\n",
        "        return prompt_cost + completion_cost\n",
        "\n",
        "    def generate_content(self, prompt, model=None, temperature=None, max_tokens=None, use_cache=None):\n",
        "        effective_model = model or self.model\n",
        "        effective_temp = temperature if temperature is not None else self.temperature\n",
        "        effective_max_tokens = max_tokens or self.max_tokens\n",
        "\n",
        "        try:\n",
        "            model_instance = genai.GenerativeModel(effective_model)\n",
        "            generation_config = {\n",
        "                \"temperature\": effective_temp,\n",
        "                \"max_output_tokens\": effective_max_tokens,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40\n",
        "            }\n",
        "\n",
        "            result = model_instance.generate_content(prompt, generation_config=generation_config)\n",
        "\n",
        "            prompt_tokens = len(prompt) // 4\n",
        "            completion_tokens = len(result.text) // 4\n",
        "\n",
        "            self.total_requests += 1\n",
        "            self.total_tokens_used += prompt_tokens + completion_tokens\n",
        "            cost = self._calculate_cost(prompt_tokens, completion_tokens)\n",
        "            self.total_cost += cost\n",
        "\n",
        "            return result.text, {\n",
        "                \"from_cache\": False,\n",
        "                \"model\": effective_model,\n",
        "                \"prompt_tokens\": prompt_tokens,\n",
        "                \"completion_tokens\": completion_tokens,\n",
        "                \"cost\": cost\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating content: {e}\")\n",
        "            return \"\", {\"error\": str(e)}\n",
        "\n",
        "    def generate_with_template(self, template, variables, model=None, temperature=None, max_tokens=None, use_cache=None):\n",
        "        filled_prompt = template\n",
        "        for var_name, var_value in variables.items():\n",
        "            filled_prompt = filled_prompt.replace(f\"{{{var_name}}}\", str(var_value))\n",
        "\n",
        "        return self.generate_content(\n",
        "            prompt=filled_prompt,\n",
        "            model=model,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens,\n",
        "            use_cache=use_cache\n",
        "        )\n",
        "\n",
        "    def get_usage_stats(self):\n",
        "        return {\n",
        "            \"total_requests\": self.total_requests,\n",
        "            \"total_tokens_used\": self.total_tokens_used,\n",
        "            \"total_cost_usd\": self.total_cost,\n",
        "            \"models_used\": list(set(req.get(\"model\", self.model) for req in self.request_history)) if self.request_history else [self.model],\n",
        "            \"average_tokens_per_request\": self.total_tokens_used / max(1, self.total_requests),\n",
        "            \"average_cost_per_request\": self.total_cost / max(1, self.total_requests)\n",
        "        }\n",
        "\n",
        "class CourseContentGenerator:\n",
        "    \"\"\"Generate educational content for courses using LLM.\"\"\"\n",
        "\n",
        "    def __init__(self, llm_client, output_dir=\"output\"):\n",
        "        self.llm_client = llm_client\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "# Template for course materials\n",
        "        self.templates = {\n",
        "            \"class_notes\": \"\"\"\n",
        "[CONTEXTO DEL CURSO]\n",
        "Título del curso: {title}\n",
        "Descripción: {description}\n",
        "Unidad actual: {unit_title}\n",
        "Tema específico: {topic}\n",
        "Objetivos de aprendizaje relacionados: {objectives}\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un profesor universitario experto en {subject_area} creando notas de clase detalladas sobre \"{topic}\" para estudiantes universitarios de nivel {course_level}.\n",
        "[ESTRUCTURA REQUERIDA]\n",
        "1. Introducción conceptual (1-2 párrafos)\n",
        "2. Fundamentos teóricos con definiciones precisas\n",
        "3. Desarrollo detallado de conceptos clave, organizados jerárquicamente\n",
        "4. Explicación de aplicaciones prácticas y ejemplos ilustrativos\n",
        "5. Conexiones con otros temas del curso\n",
        "6. Resumen de puntos principales y conclusiones\n",
        "7. Preguntas de reflexión para los estudiantes\n",
        "[REQUISITOS DE CONTENIDO]\n",
        "- Incluye definiciones rigurosas y académicamente precisas\n",
        "- Incorpora ejemplos claros que ilustren conceptos abstractos\n",
        "- Utiliza un lenguaje académico pero accesible para estudiantes universitarios\n",
        "- Incluye referencias a conceptos previos de la unidad cuando sea relevante\n",
        "- Mantén una profundidad académica apropiada para el nivel universitario\n",
        "- Incorpora la terminología específica del campo: {key_terms}\n",
        "- Evita simplificaciones excesivas o generalizaciones incorrectas\n",
        "- Asegúrate de cubrir todos los aspectos del tema mencionados en el programa del curso\n",
        "[FORMATO]\n",
        "- Utiliza encabezados y subencabezados para organizar el contenido\n",
        "- Incluye listas con viñetas para puntos importantes\n",
        "- Añade énfasis en los conceptos clave\n",
        "- Mantén una extensión aproximada de {word_count} palabras\n",
        "- Estructura los párrafos de forma clara y coherente\n",
        "Por favor, genera notas de clase completas siguiendo estas directrices.\n",
        "\"\"\",\n",
        "            \"exercises\": \"\"\"\n",
        "[CONTEXTO DEL CURSO]\n",
        "Título del curso: {title}\n",
        "Descripción: {description}\n",
        "Unidad actual: {unit_title}\n",
        "Tema específico: {topic}\n",
        "Objetivos de aprendizaje relacionados: {objectives}\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un profesor universitario experto en {subject_area} creando ejercicios prácticos sobre \"{topic}\" para estudiantes universitarios de nivel {course_level}.\n",
        "[REQUISITOS]\n",
        "- Genera {exercise_count} ejercicios con diferentes niveles de dificultad (básico, intermedio, avanzado)\n",
        "- Cada ejercicio debe incluir una explicación clara del problema\n",
        "- Proporciona la solución detallada paso a paso para cada ejercicio\n",
        "- Los ejercicios deben ayudar a comprender los conceptos teóricos del tema\n",
        "- Incluye aplicaciones prácticas y casos de estudio relevantes\n",
        "[FORMATO]\n",
        "- Organiza los ejercicios por nivel de dificultad\n",
        "- Numera cada ejercicio claramente\n",
        "- Utiliza un formato estructurado para las soluciones\n",
        "- Incluye consejos o pistas donde sea apropiado\n",
        "Por favor, genera los ejercicios prácticos siguiendo estas directrices.\n",
        "\"\"\"\n",
        "        }\n",
        "\n",
        "    def parse_course_content(self, content):\n",
        "        \"\"\"Parse course content from text format.\"\"\"\n",
        "        lines = content.strip().split('\\n')\n",
        "        course_info = {}\n",
        "\n",
        "        # Extract basic course information\n",
        "        title_line = next((line for line in lines if line.startswith(\"Contenido del curso\")), \"\")\n",
        "        if title_line:\n",
        "            course_info[\"title\"] = title_line.replace(\"Contenido del curso\", \"\").strip()\n",
        "\n",
        "        # Extract units\n",
        "        units = []\n",
        "        current_unit = None\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Check if this is a unit heading (assumes \"1. Unit Name\" format)\n",
        "            if line[0].isdigit() and line[1:3] in ['. ', '- ']:\n",
        "                if current_unit:\n",
        "                    units.append(current_unit)\n",
        "                unit_number = line[0]\n",
        "                unit_name = line[3:].strip()\n",
        "                current_unit = {\n",
        "                    \"number\": unit_number,\n",
        "                    \"name\": unit_name,\n",
        "                    \"topics\": []\n",
        "                }\n",
        "\n",
        "        # Add the last unit if exists\n",
        "        if current_unit:\n",
        "            units.append(current_unit)\n",
        "\n",
        "        course_info[\"units\"] = units\n",
        "\n",
        "        # Authorship information\n",
        "        author_section = next((i for i, line in enumerate(lines) if line.startswith(\"Autor:\")), -1)\n",
        "        if author_section >= 0:\n",
        "            author_lines = []\n",
        "            for i in range(author_section, min(author_section + 5, len(lines))):\n",
        "                if lines[i].strip():\n",
        "                    author_lines.append(lines[i].strip())\n",
        "            course_info[\"author\"] = \" \".join(author_lines)\n",
        "\n",
        "        return course_info\n",
        "\n",
        "    def generate_course_materials(self, course_info, material_type=\"class_notes\"):\n",
        "        \"\"\"Generate course materials based on course info.\"\"\"\n",
        "        logger.info(f\"Generating {material_type} for course: {course_info.get('title', 'Unknown')}\")\n",
        "\n",
        "        template = self.templates.get(material_type)\n",
        "        if not template:\n",
        "            logger.error(f\"No template found for material type: {material_type}\")\n",
        "            return None\n",
        "\n",
        "        materials = {}\n",
        "        units = course_info.get(\"units\", [])\n",
        "\n",
        "        for unit in units:\n",
        "            unit_number = unit.get(\"number\")\n",
        "            unit_name = unit.get(\"name\")\n",
        "            unit_key = f\"unit_{unit_number}\"\n",
        "\n",
        "            logger.info(f\"Generating materials for Unit {unit_number}: {unit_name}\")\n",
        "\n",
        "            # Prepare variables for template\n",
        "            variables = {\n",
        "                \"title\": course_info.get(\"title\", \"\"),\n",
        "                \"description\": course_info.get(\"description\", \"Course description not available\"),\n",
        "                \"unit_title\": unit_name,\n",
        "                \"topic\": unit_name,\n",
        "                \"objectives\": \"Understand core concepts and applications of this unit\",\n",
        "                \"subject_area\": course_info.get(\"title\", \"\").split()[0],  # Simple extraction of subject\n",
        "                \"course_level\": \"pregrado\",\n",
        "                \"key_terms\": \"\",\n",
        "                \"word_count\": \"1500\",\n",
        "                \"exercise_count\": \"5\"\n",
        "            }\n",
        "\n",
        "            # Generate content\n",
        "            content, metadata = self.llm_client.generate_with_template(\n",
        "                template=template,\n",
        "                variables=variables\n",
        "            )\n",
        "\n",
        "            materials[unit_key] = content\n",
        "\n",
        "            # Log generation\n",
        "            tokens = metadata.get(\"prompt_tokens\", 0) + metadata.get(\"completion_tokens\", 0)\n",
        "            logger.info(f\"Generated {material_type} for Unit {unit_number}. Tokens: {tokens}\")\n",
        "\n",
        "        return materials\n",
        "\n",
        "    def save_materials(self, materials, course_info, material_type, format=\"markdown\"):\n",
        "        \"\"\"Save generated materials to files.\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        material_dir = self.output_dir / material_type / timestamp\n",
        "        material_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        saved_files = []\n",
        "\n",
        "        # Save individual unit materials\n",
        "        for unit_key, content in materials.items():\n",
        "            # Clean filename\n",
        "            filename = f\"{unit_key}_{material_type}\"\n",
        "\n",
        "            # Save as markdown\n",
        "            md_path = material_dir / f\"{filename}.md\"\n",
        "            with open(md_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(content)\n",
        "            saved_files.append(md_path)\n",
        "\n",
        "            # Convert to PDF if requested\n",
        "            if format == \"pdf\":\n",
        "                try:\n",
        "                    pdf_path = material_dir / f\"{filename}.pdf\"\n",
        "                    html = markdown2.markdown(content)\n",
        "                    extra_args = ['--pdf-engine=xelatex', '-V', 'mainfont=Latin Modern Roman']\n",
        "                    pypandoc.convert_text(html, 'pdf', format='html', outputfile=str(pdf_path), extra_args=extra_args)\n",
        "                    saved_files.append(pdf_path)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error converting to PDF: {e}\")\n",
        "\n",
        "        # Save combined materials\n",
        "        if len(materials) > 1:\n",
        "            combined_content = f\"# {course_info.get('title', 'Course')} - {material_type.replace('_', ' ').title()}\\n\\n\"\n",
        "            combined_content += f\"Author: {course_info.get('author', 'Unknown')}\\n\\n\"\n",
        "\n",
        "            for unit_key, content in materials.items():\n",
        "                unit_number = unit_key.split('_')[1]\n",
        "                unit_name = next((u.get('name', '') for u in course_info.get('units', []) if u.get('number') == unit_number), '')\n",
        "                combined_content += f\"## Unit {unit_number}: {unit_name}\\n\\n\"\n",
        "                combined_content += content\n",
        "                combined_content += \"\\n\\n---\\n\\n\"\n",
        "\n",
        "            # Save combined markdown\n",
        "            combined_path = material_dir / f\"{course_info.get('title', 'course')}_{material_type}.md\"\n",
        "            with open(combined_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(combined_content)\n",
        "            saved_files.append(combined_path)\n",
        "\n",
        "            # Convert to PDF if requested\n",
        "            if format == \"pdf\":\n",
        "                try:\n",
        "                    pdf_path = material_dir / f\"{course_info.get('title', 'course')}_{material_type}.pdf\"\n",
        "                    html = markdown2.markdown(combined_content)\n",
        "                    extra_args = ['--pdf-engine=xelatex', '-V', 'mainfont=Latin Modern Roman']\n",
        "                    pypandoc.convert_text(html, 'pdf', format='html', outputfile=str(pdf_path), extra_args=extra_args)\n",
        "                    saved_files.append(pdf_path)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error converting combined content to PDF: {e}\")\n",
        "\n",
        "        logger.info(f\"Saved {len(saved_files)} files to {material_dir}\")\n",
        "        return saved_files\n",
        "\n",
        "def generate_course_materials(course_content=None, output_dir=\"output\", model=\"gemini-2.0-flash-001\", output_format=\"markdown\", api_key=None):\n",
        "    \"\"\"Generate educational materials - designed to be called directly.\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"API key is required\")\n",
        "\n",
        "    # If no course content provided, use a default example\n",
        "    if not course_content:\n",
        "        course_content = \"\"\"\n",
        "Contenido del curso Cálculo diferencial.\n",
        "Unidades:\n",
        "1. Introducción a la derivada\n",
        "2. Derivada de la función compuesta\n",
        "3. Aplicaciones de la derivada en problemas de razón de cambio\n",
        "\n",
        "Autor: Juan David Ospina Arango\n",
        "Profesor Asociado\n",
        "Departamento de Ciencias de la Computación y de la Decisión\n",
        "Universidad Nacional de Colombia\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Initialize Gemini client with provided API key\n",
        "        gemini_client = GeminiClient(\n",
        "            api_key=api_key,\n",
        "            model=model,\n",
        "            temperature=0.4,\n",
        "            max_tokens=8192,\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "        # Initialize content generator\n",
        "        generator = CourseContentGenerator(\n",
        "            llm_client=gemini_client,\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "\n",
        "        # Parse course content\n",
        "        course_info = generator.parse_course_content(course_content)\n",
        "\n",
        "        # Generate class notes\n",
        "        class_notes = generator.generate_course_materials(\n",
        "            course_info=course_info,\n",
        "            material_type=\"class_notes\"\n",
        "        )\n",
        "\n",
        "        # Save class notes\n",
        "        notes_files = generator.save_materials(\n",
        "            materials=class_notes,\n",
        "            course_info=course_info,\n",
        "            material_type=\"class_notes\",\n",
        "            format=output_format\n",
        "        )\n",
        "\n",
        "        # Generate exercises\n",
        "        exercises = generator.generate_course_materials(\n",
        "            course_info=course_info,\n",
        "            material_type=\"exercises\"\n",
        "        )\n",
        "\n",
        "        # Save exercises\n",
        "        exercise_files = generator.save_materials(\n",
        "            materials=exercises,\n",
        "            course_info=course_info,\n",
        "            material_type=\"exercises\",\n",
        "            format=output_format\n",
        "        )\n",
        "\n",
        "        # Print usage statistics\n",
        "        usage_stats = gemini_client.get_usage_stats()\n",
        "        logger.info(f\"Total requests: {usage_stats['total_requests']}\")\n",
        "        logger.info(f\"Total tokens used: {usage_stats['total_tokens_used']}\")\n",
        "        logger.info(f\"Estimated cost: ${usage_stats['total_cost_usd']:.4f}\")\n",
        "\n",
        "        logger.info(f\"Materials generated successfully. Check the {output_dir} directory for files.\")\n",
        "        return notes_files, exercise_files, usage_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in content generation: {e}\")\n",
        "        return None, None, {\"error\": str(e)}\n",
        "\n",
        "# Run the generator with your course content and API key\n",
        "notes_files, exercise_files, usage_stats = generate_course_materials(\n",
        "    course_content=course_content,\n",
        "    output_dir=\"output_materials\",\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    output_format=\"markdown\",\n",
        "    api_key=api_key  # Make sure to replace this with your real API key\n",
        ")\n",
        "\n",
        "# Print results\n",
        "if notes_files and exercise_files:\n",
        "    print(f\"\\nSUCCESS! Generated {len(notes_files)} note files and {len(exercise_files)} exercise files\")\n",
        "    print(f\"Total cost: ${usage_stats['total_cost_usd']:.4f}\")\n",
        "    print(f\"Check the output_materials directory for your files!\")\n",
        "else:\n",
        "    print(\"\\nERROR: Failed to generate materials.\")\n",
        "    print(\"Error details:\", usage_stats.get(\"error\", \"Unknown error\"))"
      ],
      "metadata": {
        "id": "xVg9zd6HXC8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "54eead0d-a064-475a-bd0f-92b8d42a9510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SUCCESS! Generated 4 note files and 4 exercise files\n",
            "Total cost: $0.0024\n",
            "Check the output_materials directory for your files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Course content\n",
        "course_content = \"\"\"\n",
        "Contenido del curso Analisis y Diseño de algoritmos.\n",
        "Unidades:\n",
        "1. Introducción a Big O\n",
        "2. Algoritmos dinamicos\n",
        "3. Divide y venceras\n",
        "\n",
        "Autor: Julian Moreno\n",
        "Departamento de Ciencias de la Computación y de la Decisión\n",
        "Universidad Nacional de Colombia\n",
        "\"\"\"\n",
        "\n",
        "# Your API key\n",
        "api_key = \"Mi_API\"  # Replace with your real Google API key\n",
        "\n",
        "# Run the generator with your course content and API key\n",
        "notes_files, exercise_files, usage_stats = generate_course_materials(\n",
        "    course_content=course_content,\n",
        "    output_dir=\"output_materials\",\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    output_format=\"markdown\",\n",
        "    api_key=api_key  # Make sure to replace this with your real API key\n",
        ")\n",
        "\n",
        "# Print results\n",
        "if notes_files and exercise_files:\n",
        "    print(f\"\\nSUCCESS! Generated {len(notes_files)} note files and {len(exercise_files)} exercise files\")\n",
        "    print(f\"Total cost: ${usage_stats['total_cost_usd']:.4f}\")\n",
        "    print(f\"Check the output_materials directory for your files!\")\n",
        "else:\n",
        "    print(\"\\nERROR: Failed to generate materials.\")\n",
        "    print(\"Error details:\", usage_stats.get(\"error\", \"Unknown error\"))"
      ],
      "metadata": {
        "id": "2gSk0BY8YMH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "152996e0-65f7-4e8d-c5b9-cb309dbcc2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SUCCESS! Generated 4 note files and 4 exercise files\n",
            "Total cost: $0.0033\n",
            "Check the output_materials directory for your files!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extensión de plantillas para los materiales adicionales requeridos\n",
        "additional_templates = {\n",
        "    \"discussion_questions\": \"\"\"\n",
        "[CONTEXTO DEL CURSO]\n",
        "Título del curso: {title}\n",
        "Descripción: {description}\n",
        "Unidad actual: {unit_title}\n",
        "Tema específico: {topic}\n",
        "Objetivos de aprendizaje relacionados: {objectives}\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un profesor universitario experto en {subject_area} creando preguntas de discusión para \"{topic}\" para estudiantes universitarios de nivel {course_level}.\n",
        "[REQUISITOS]\n",
        "- Genera 5-7 preguntas de discusión que fomenten el pensamiento crítico\n",
        "- Las preguntas deben explorar diferentes aspectos del tema\n",
        "- Incluye preguntas que conecten con aplicaciones prácticas o casos reales\n",
        "- Fomenta la reflexión sobre implicaciones éticas cuando sea relevante\n",
        "- Incluye preguntas que relacionen este tema con otros del curso\n",
        "[FORMATO]\n",
        "- Organiza las preguntas en secciones temáticas\n",
        "- Para cada pregunta, incluye una breve nota sobre los aspectos que busca explorar\n",
        "- Añade sugerencias para facilitar la discusión en clase\n",
        "Por favor, genera preguntas de discusión siguiendo estas directrices.\n",
        "\"\"\",\n",
        "\n",
        "    \"learning_objectives\": \"\"\"\n",
        "[CONTEXTO DEL CURSO]\n",
        "Título del curso: {title}\n",
        "Descripción: {description}\n",
        "Unidad actual: {unit_title}\n",
        "Tema específico: {topic}\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un diseñador curricular experto creando objetivos de aprendizaje para el tema \"{topic}\" en un curso universitario de {subject_area} de nivel {course_level}.\n",
        "[REQUISITOS]\n",
        "- Utiliza la taxonomía de Bloom para diferentes niveles cognitivos\n",
        "- Genera 5-8 objetivos claros y medibles\n",
        "- Incluye objetivos para conocimiento, comprensión, aplicación, análisis y evaluación\n",
        "- Los objetivos deben ser específicos y alcanzables en el contexto del curso\n",
        "- Asegúrate que sean relevantes para las competencias del área de {subject_area}\n",
        "[FORMATO]\n",
        "- Organiza los objetivos por nivel cognitivo\n",
        "- Utiliza verbos de acción específicos al inicio de cada objetivo\n",
        "- Incluye una breve explicación de cómo cada objetivo contribuye al dominio del tema\n",
        "- Añade sugerencias de actividades que ayuden a lograr cada objetivo\n",
        "Por favor, genera objetivos de aprendizaje siguiendo estas directrices.\n",
        "\"\"\",\n",
        "\n",
        "    \"suggested_readings\": \"\"\"\n",
        "[CONTEXTO DEL CURSO]\n",
        "Título del curso: {title}\n",
        "Descripción: {description}\n",
        "Unidad actual: {unit_title}\n",
        "Tema específico: {topic}\n",
        "Objetivos de aprendizaje relacionados: {objectives}\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un bibliotecario académico experto en {subject_area} recomendando recursos de lectura para el tema \"{topic}\" para estudiantes universitarios de nivel {course_level}.\n",
        "[REQUISITOS]\n",
        "- Recomienda 8-10 recursos académicos relevantes (libros, artículos, recursos web)\n",
        "- Incluye tanto recursos fundamentales clásicos como literatura reciente\n",
        "- Para cada recurso académico, proporciona: autor, título, año, editorial/revista y una breve descripción\n",
        "- Categoriza las lecturas (básicas, complementarias, avanzadas)\n",
        "- Incluye al menos 2-3 recursos en español y el resto en inglés\n",
        "- Añade comentarios sobre la relevancia específica de cada recurso para el tema\n",
        "[FORMATO]\n",
        "- Organiza los recursos por categoría y relevancia\n",
        "- Proporciona referencias en formato APA\n",
        "- Incluye una breve justificación para cada recurso\n",
        "- Si es posible, sugiere capítulos o secciones específicas\n",
        "Por favor, genera recomendaciones de lecturas siguiendo estas directrices.\n",
        "\"\"\"\n",
        "}\n",
        "\n",
        "# Actualiza las plantillas existentes en tu clase CourseContentGenerator\n",
        "# Esta celda debe ejecutarse después de haber definido la clase CourseContentGenerator\n",
        "def update_course_generator_templates():\n",
        "    # Referencia al generador de contenido global o crea uno nuevo\n",
        "    try:\n",
        "        # Intenta acceder a un generador ya definido en el espacio global\n",
        "        global generator\n",
        "        if 'generator' in globals():\n",
        "            generator.templates.update(additional_templates)\n",
        "            print(\"Plantillas actualizadas en el generador existente.\")\n",
        "        else:\n",
        "            # Si no existe, crea un mensaje informativo\n",
        "            print(\"No se encontró el generador. Ejecuta primero la celda que define CourseContentGenerator.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al actualizar plantillas: {e}\")"
      ],
      "metadata": {
        "id": "_eQKsywYvJoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_course_content(response):\n",
        "    \"\"\"\n",
        "    Extrae y retorna el contenido generado en formato de código Python\n",
        "    a partir del objeto de respuesta del modelo.\n",
        "    \"\"\"\n",
        "    # Intentar acceder como objeto con atributos\n",
        "\n",
        "    try:\n",
        "        return response.candidates[0].content.parts[0].text\n",
        "\n",
        "    except AttributeError:\n",
        "        # Si falla, intentar acceder como diccionario\n",
        "        try:\n",
        "            print(\"Modelo Gemini inicializado.2\")\n",
        "            return response['candidates'][0]['content']['parts'][0]['text']\n",
        "        except (KeyError, TypeError):\n",
        "            print(\"Modelo Gemini inicializado.3\")\n",
        "            raise ValueError(\"No se pudo extraer el contenido de la respuesta.\")\n",
        "\n",
        "def generate_course_content(custom_prompt):\n",
        "    \"\"\"\n",
        "    Llama al modelo Gemini con el prompt proporcionado y retorna el contenido\n",
        "    en el formato solicitado.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa el modelo Gemini\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash-001')\n",
        "    print(\"Modelo Gemini inicializado.   1\")\n",
        "    # Genera la respuesta usando el prompt\n",
        "    response = model.generate_content(custom_prompt)\n",
        "\n",
        "    # Extrae y retorna el contenido formateado\n",
        "    return extract_course_content(response)"
      ],
      "metadata": {
        "id": "PlJD1zypsA-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CourseFileParser:\n",
        "    \"\"\"Parse course content from various file formats (PDF, DOCX, TXT).\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_file(file_path):\n",
        "        \"\"\"Parse a file based on its extension.\"\"\"\n",
        "        import os\n",
        "        import logging\n",
        "        from pathlib import Path\n",
        "\n",
        "        file_path = Path(file_path)\n",
        "        ext = file_path.suffix.lower()\n",
        "\n",
        "        if ext == '.txt':\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                return f.read()\n",
        "        elif ext == '.docx':\n",
        "            try:\n",
        "                import docx\n",
        "                doc = docx.Document(file_path)\n",
        "                content = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "                return content\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error parsing DOCX file: {e}\")\n",
        "                return None\n",
        "        elif ext == '.pdf':\n",
        "            try:\n",
        "                # First attempt with PyPDF2\n",
        "                try:\n",
        "                    import PyPDF2\n",
        "                    with open(file_path, 'rb') as f:\n",
        "                        reader = PyPDF2.PdfReader(f)\n",
        "                        content = \"\"\n",
        "                        for page_num in range(len(reader.pages)):\n",
        "                            page = reader.pages[page_num]\n",
        "                            text = page.extract_text()\n",
        "                            if text:\n",
        "                                content += text + \"\\n\\n\"\n",
        "\n",
        "                        if content.strip():  # If we got content, return it\n",
        "                            return content\n",
        "                except Exception as e:\n",
        "                    logging.warning(f\"PyPDF2 failed: {e}, trying pdfplumber...\")\n",
        "\n",
        "                # If PyPDF2 fails or returns empty content, try pdfplumber\n",
        "                import pdfplumber\n",
        "                content = \"\"\n",
        "                with pdfplumber.open(file_path) as pdf:\n",
        "                    for page in pdf.pages:\n",
        "                        text = page.extract_text()\n",
        "                        if text:\n",
        "                            content += text + \"\\n\\n\"\n",
        "\n",
        "                if not content.strip():\n",
        "                    # If both methods fail to extract text, PDF might be scanned\n",
        "                    logging.warning(\"PDF may be scanned/image-based. Consider OCR.\")\n",
        "\n",
        "                return content\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error parsing PDF file: {e}\")\n",
        "                return None\n",
        "        else:\n",
        "            logging.error(f\"Unsupported file format: {ext}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def upload_and_parse():\n",
        "        \"\"\"Upload and parse a file directly in Colab.\"\"\"\n",
        "        from google.colab import files\n",
        "        import io\n",
        "        import os\n",
        "        import logging\n",
        "\n",
        "        print(\"Por favor, sube un archivo de curso (PDF, DOCX o TXT):\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename, content in uploaded.items():\n",
        "            temp_path = f\"/tmp/{filename}\"\n",
        "            with open(temp_path, 'wb') as f:\n",
        "                f.write(content)\n",
        "\n",
        "            parsed_content = CourseFileParser.parse_file(temp_path)\n",
        "            os.remove(temp_path)  # Limpiar archivos temporales\n",
        "            custom_prompt = \"\"\"\n",
        "            Convierte el siguiente contenido del curso  en un string  que  siguiendo EXACTAMENTE el siguiente formato:\n",
        "\n",
        "\n",
        "\n",
        "            Contenido del curso: [Nombre del curso]\n",
        "            Unidades:\n",
        "            1. [Título de la unidad 1]\n",
        "            2. [Título de la unidad 2]\n",
        "            3. [Título de la unidad 3]\n",
        "\n",
        "            Autor: [Nombre del autor]\n",
        "            [Cargo o posición]\n",
        "            [Departamento o información adicional]\n",
        "            Universidad Nacional de Colombia\n",
        "\n",
        "\n",
        "            En la conversión, reemplaza los campos entre corchetes con la información correspondiente del PDF (por ejemplo, para el curso \"Análisis y Diseño de Algoritmos (2024-2)\", ubica de forma coherente los objetivos, requisitos, evaluación, metodología y demás datos).\n",
        "            \"\"\" + parsed_content\n",
        "            if parsed_content and parsed_content.strip():\n",
        "                print(f\"Archivo {filename} procesado exitosamente.\")\n",
        "\n",
        "                new_parsed = generate_course_content(custom_prompt)\n",
        "                return new_parsed\n",
        "            else:\n",
        "                print(f\"Error al procesar {filename} o el archivo no contiene texto extraíble.\")\n",
        "                return None\n",
        "\n"
      ],
      "metadata": {
        "id": "xizPDof_udtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentEvaluator:\n",
        "    \"\"\"Evaluates the quality of generated educational content.\"\"\"\n",
        "\n",
        "    def __init__(self, llm_client):\n",
        "        self.llm_client = llm_client\n",
        "        self.evaluation_templates = {\n",
        "            \"relevance\": \"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un experto en evaluación educativa. Evalúa la relevancia y calidad del siguiente contenido educativo con respecto al tema \"{topic}\" y los objetivos de aprendizaje: \"{objectives}\".\n",
        "\n",
        "[CONTENIDO A EVALUAR]\n",
        "{content_sample}\n",
        "\n",
        "[CRITERIOS DE EVALUACIÓN]\n",
        "1. Relevancia temática (1-10): ¿El contenido aborda directamente el tema especificado?\n",
        "2. Alineación con objetivos (1-10): ¿El contenido permite alcanzar los objetivos de aprendizaje?\n",
        "3. Precisión académica (1-10): ¿Los conceptos, definiciones y explicaciones son precisos?\n",
        "4. Profundidad adecuada (1-10): ¿El contenido tiene la profundidad apropiada para el nivel académico?\n",
        "5. Organización y estructura (1-10): ¿El contenido está bien organizado y estructurado?\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "Proporciona una puntuación de 1-10 para cada criterio, seguida de una breve justificación.\n",
        "Al final, calcula una puntuación global (promedio) y ofrece 2-3 sugerencias específicas de mejora.\n",
        "Tu evaluación debe ser rigurosa, objetiva y constructiva.\n",
        "\"\"\",\n",
        "            \"readability\": \"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un experto en comunicación educativa. Evalúa la legibilidad y claridad pedagógica del siguiente contenido educativo para estudiantes de nivel {course_level}.\n",
        "\n",
        "[CONTENIDO A EVALUAR]\n",
        "{content_sample}\n",
        "\n",
        "[CRITERIOS DE EVALUACIÓN]\n",
        "1. Claridad explicativa (1-10): ¿Las explicaciones son claras y comprensibles?\n",
        "2. Lenguaje apropiado (1-10): ¿El lenguaje es apropiado para el nivel académico?\n",
        "3. Ejemplificación (1-10): ¿Se utilizan ejemplos efectivos para ilustrar conceptos?\n",
        "4. Recursos visuales/organizativos (1-10): ¿El contenido utiliza recursos para facilitar la comprensión?\n",
        "5. Accesibilidad cognitiva (1-10): ¿El contenido es accesible para diferentes estilos de aprendizaje?\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "Proporciona una puntuación de 1-10 para cada criterio, seguida de una breve justificación.\n",
        "Al final, calcula una puntuación global (promedio) y ofrece 2-3 sugerencias específicas de mejora.\n",
        "Tu evaluación debe centrarse en aspectos pedagógicos y comunicativos.\n",
        "\"\"\",\n",
        "            \"terminology\": \"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un experto lingüista especializado en {subject_area}. Evalúa el uso apropiado de terminología especializada en el siguiente contenido educativo.\n",
        "\n",
        "[CONTENIDO A EVALUAR]\n",
        "{content_sample}\n",
        "\n",
        "[CRITERIOS DE EVALUACIÓN]\n",
        "1. Precisión terminológica (1-10): ¿Los términos técnicos se utilizan con precisión?\n",
        "2. Consistencia (1-10): ¿La terminología se utiliza de manera consistente en todo el contenido?\n",
        "3. Explicación de términos (1-10): ¿Los términos técnicos se introducen y explican adecuadamente?\n",
        "4. Densidad terminológica (1-10): ¿La densidad de términos técnicos es adecuada para el nivel?\n",
        "5. Contextualización (1-10): ¿Los términos se presentan en contextos relevantes?\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "Proporciona una puntuación de 1-10 para cada criterio, seguida de una breve justificación.\n",
        "Incluye una lista de 5-10 términos clave identificados en el contenido.\n",
        "Al final, calcula una puntuación global (promedio) y ofrece 2-3 sugerencias específicas de mejora.\n",
        "\"\"\",\n",
        "            \"consistency\": \"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un editor académico experto. Evalúa la consistencia interna del siguiente contenido educativo.\n",
        "\n",
        "[CONTENIDO A EVALUAR]\n",
        "{content_sample}\n",
        "\n",
        "[CRITERIOS DE EVALUACIÓN]\n",
        "1. Consistencia conceptual (1-10): ¿Los conceptos se utilizan de manera consistente?\n",
        "2. Consistencia estructural (1-10): ¿La estructura y organización es consistente?\n",
        "3. Consistencia estilística (1-10): ¿El estilo de escritura es consistente?\n",
        "4. Progresión lógica (1-10): ¿El contenido progresa lógicamente sin contradicciones?\n",
        "5. Concordancia con objetivos (1-10): ¿El contenido es consistente con los objetivos declarados?\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "Proporciona una puntuación de 1-10 para cada criterio, seguida de una breve justificación.\n",
        "Identifica cualquier inconsistencia específica encontrada.\n",
        "Al final, calcula una puntuación global (promedio) y ofrece 2-3 sugerencias específicas de mejora.\n",
        "\"\"\"\n",
        "        }\n",
        "\n",
        "    def _truncate_content(self, content, max_length=4000):\n",
        "        \"\"\"Truncate content to avoid exceeding token limits.\"\"\"\n",
        "        if len(content) <= max_length:\n",
        "            return content\n",
        "\n",
        "        # Tomar primeras y últimas partes para mantener contexto\n",
        "        first_part = content[:max_length//2]\n",
        "        last_part = content[-max_length//2:]\n",
        "        return first_part + \"\\n\\n[...contenido omitido por brevedad...]\\n\\n\" + last_part\n",
        "\n",
        "    def evaluate_content(self, content, topic, objectives, material_type, course_level=\"pregrado\", subject_area=\"\"):\n",
        "        \"\"\"Evaluate content using different criteria.\"\"\"\n",
        "        content_sample = self._truncate_content(content)\n",
        "        results = {}\n",
        "\n",
        "        # Evaluar relevancia\n",
        "        relevance_prompt = self.evaluation_templates[\"relevance\"].format(\n",
        "            topic=topic,\n",
        "            objectives=objectives,\n",
        "            content_sample=content_sample\n",
        "        )\n",
        "        relevance_result, _ = self.llm_client.generate_content(relevance_prompt)\n",
        "        results[\"relevance\"] = relevance_result\n",
        "\n",
        "        # Evaluar legibilidad\n",
        "        readability_prompt = self.evaluation_templates[\"readability\"].format(\n",
        "            course_level=course_level,\n",
        "            content_sample=content_sample\n",
        "        )\n",
        "        readability_result, _ = self.llm_client.generate_content(readability_prompt)\n",
        "        results[\"readability\"] = readability_result\n",
        "\n",
        "        # Evaluar terminología\n",
        "        terminology_prompt = self.evaluation_templates[\"terminology\"].format(\n",
        "            subject_area=subject_area,\n",
        "            content_sample=content_sample\n",
        "        )\n",
        "        terminology_result, _ = self.llm_client.generate_content(terminology_prompt)\n",
        "        results[\"terminology\"] = terminology_result\n",
        "\n",
        "        # Evaluar consistencia\n",
        "        consistency_prompt = self.evaluation_templates[\"consistency\"].format(\n",
        "            content_sample=content_sample\n",
        "        )\n",
        "        consistency_result, _ = self.llm_client.generate_content(consistency_prompt)\n",
        "        results[\"consistency\"] = consistency_result\n",
        "\n",
        "        return results\n",
        "\n",
        "    def generate_evaluation_report(self, evaluation_results, material_type, topic):\n",
        "        \"\"\"Generate a comprehensive evaluation report based on individual evaluations.\"\"\"\n",
        "        report_prompt = f\"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un experto en evaluación educativa. Genera un informe de evaluación completo para el material de tipo \"{material_type}\" sobre el tema \"{topic}\", basado en las siguientes evaluaciones específicas:\n",
        "\n",
        "[EVALUACIÓN DE RELEVANCIA]\n",
        "{evaluation_results.get('relevance', 'No disponible')}\n",
        "\n",
        "[EVALUACIÓN DE LEGIBILIDAD]\n",
        "{evaluation_results.get('readability', 'No disponible')}\n",
        "\n",
        "[EVALUACIÓN DE TERMINOLOGÍA]\n",
        "{evaluation_results.get('terminology', 'No disponible')}\n",
        "\n",
        "[EVALUACIÓN DE CONSISTENCIA]\n",
        "{evaluation_results.get('consistency', 'No disponible')}\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "1. Resumen Ejecutivo: Síntesis general de la calidad del material (1 párrafo)\n",
        "2. Fortalezas Principales: 3-5 fortalezas clave identificadas\n",
        "3. Áreas de Mejora: 3-5 áreas específicas de mejora\n",
        "4. Puntuación Global: Calificación general considerando todos los criterios (escala 1-10)\n",
        "5. Recomendaciones Específicas: Sugerencias concretas para mejorar el material\n",
        "\n",
        "Tu informe debe ser claro, objetivo y orientado a mejorar la calidad educativa del material.\n",
        "\"\"\"\n",
        "\n",
        "        report, _ = self.llm_client.generate_content(report_prompt)\n",
        "        return report"
      ],
      "metadata": {
        "id": "Cii3K5FEudqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_evaluate_complete_materials(course_content=None, file_path=None, output_dir=\"output_complete\",\n",
        "                                            model=\"gemini-2.0-flash-001\", output_format=\"markdown\", api_key=None):\n",
        "    \"\"\"Generate and evaluate all required educational materials for a course.\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"API key is required\")\n",
        "\n",
        "    # Obtener el contenido del curso\n",
        "    if file_path  :\n",
        "        course_content = CourseFileParser.upload_and_parse()\n",
        "\n",
        "    elif not course_content:\n",
        "        # Usar el ejemplo predeterminado\n",
        "        course_content = \"\"\"\n",
        "Contenido del curso Cálculo diferencial.\n",
        "Unidades:\n",
        "1. Introducción a la derivada\n",
        "2. Derivada de la función compuesta\n",
        "3. Aplicaciones de la derivada en problemas de razón de cambio\n",
        "\n",
        "Autor: Juan David Ospina Arango\n",
        "Profesor Asociado\n",
        "Departamento de Ciencias de la Computación y de la Decisión\n",
        "Universidad Nacional de Colombia\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Inicializar cliente de Gemini\n",
        "        gemini_client = GeminiClient(\n",
        "            api_key=api_key,\n",
        "            model=model,\n",
        "            temperature=0.4,\n",
        "            max_tokens=8192,\n",
        "            use_cache=True\n",
        "        )\n",
        "\n",
        "        # Inicializar generador de contenido\n",
        "        generator = CourseContentGenerator(\n",
        "            llm_client=gemini_client,\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "\n",
        "        # Actualizar plantillas con las adicionales\n",
        "        generator.templates.update(additional_templates)\n",
        "\n",
        "        # Inicializar evaluador\n",
        "        evaluator = ContentEvaluator(llm_client=gemini_client)\n",
        "\n",
        "        # Analizar contenido del curso\n",
        "        course_info = generator.parse_course_content(course_content)\n",
        "\n",
        "        # Definir tipos de material a generar\n",
        "        material_types = [\"class_notes\", \"exercises\", \"discussion_questions\",\n",
        "                          \"learning_objectives\", \"suggested_readings\"]\n",
        "\n",
        "        all_materials = {}\n",
        "        all_evaluations = {}\n",
        "        all_files = []\n",
        "\n",
        "        # Generar cada tipo de material\n",
        "        for material_type in material_types:\n",
        "            logger.info(f\"Generando material: {material_type}\")\n",
        "\n",
        "            # Generar el material\n",
        "            materials = generator.generate_course_materials(\n",
        "                course_info=course_info,\n",
        "                material_type=material_type\n",
        "            )\n",
        "\n",
        "            all_materials[material_type] = materials\n",
        "\n",
        "            # Guardar el material\n",
        "            files = generator.save_materials(\n",
        "                materials=materials,\n",
        "                course_info=course_info,\n",
        "                material_type=material_type,\n",
        "                format=output_format\n",
        "            )\n",
        "\n",
        "            all_files.extend(files)\n",
        "\n",
        "            # Evaluar el material\n",
        "            evaluations = {}\n",
        "            for unit_key, content in materials.items():\n",
        "                unit_number = unit_key.split('_')[1]\n",
        "                unit = next((u for u in course_info.get(\"units\", []) if u.get(\"number\") == unit_number), None)\n",
        "\n",
        "                if unit:\n",
        "                    # Evaluar contenido\n",
        "                    topic = unit.get(\"name\", \"\")\n",
        "                    objectives = f\"Comprender conceptos y aplicaciones de {topic}\"\n",
        "                    subject_area = course_info.get(\"title\", \"\").split()[0]\n",
        "\n",
        "                    eval_results = evaluator.evaluate_content(\n",
        "                        content=content,\n",
        "                        topic=topic,\n",
        "                        objectives=objectives,\n",
        "                        material_type=material_type,\n",
        "                        subject_area=subject_area\n",
        "                    )\n",
        "\n",
        "                    # Generar informe de evaluación\n",
        "                    eval_report = evaluator.generate_evaluation_report(\n",
        "                        evaluation_results=eval_results,\n",
        "                        material_type=material_type,\n",
        "                        topic=topic\n",
        "                    )\n",
        "\n",
        "                    evaluations[unit_key] = {\n",
        "                        \"detailed_evaluations\": eval_results,\n",
        "                        \"evaluation_report\": eval_report\n",
        "                    }\n",
        "\n",
        "            all_evaluations[material_type] = evaluations\n",
        "\n",
        "        # Guardar evaluaciones\n",
        "        eval_dir = Path(output_dir) / \"evaluations\"\n",
        "        eval_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for material_type, evaluations in all_evaluations.items():\n",
        "            eval_file = eval_dir / f\"{material_type}_evaluations.md\"\n",
        "\n",
        "            with open(eval_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"# Evaluaciones para {material_type}\\n\\n\")\n",
        "\n",
        "                for unit_key, eval_data in evaluations.items():\n",
        "                    unit_number = unit_key.split('_')[1]\n",
        "                    f.write(f\"## Unidad {unit_number}\\n\\n\")\n",
        "                    f.write(\"### Informe de Evaluación\\n\\n\")\n",
        "                    f.write(eval_data[\"evaluation_report\"])\n",
        "                    f.write(\"\\n\\n---\\n\\n\")\n",
        "\n",
        "            all_files.append(eval_file)\n",
        "\n",
        "        # Generar informe general\n",
        "        summary_prompt = f\"\"\"\n",
        "[INSTRUCCIÓN]\n",
        "Actúa como un experto en educación. Genera un informe resumido sobre la calidad general del conjunto completo de materiales educativos generados para el curso \"{course_info.get('title', '')}\".\n",
        "\n",
        "[MATERIALES GENERADOS]\n",
        "Se han generado los siguientes tipos de materiales:\n",
        "{', '.join(material_types)}\n",
        "\n",
        "Para {len(course_info.get('units', []))} unidades del curso.\n",
        "\n",
        "[FORMATO REQUERIDO]\n",
        "1. Resumen Ejecutivo: Visión general de la calidad del conjunto completo de materiales\n",
        "2. Fortalezas del Sistema: Aspectos positivos identificados en los materiales generados\n",
        "3. Áreas de Mejora: Aspectos que podrían mejorarse en futuras iteraciones\n",
        "4. Recomendaciones: Sugerencias concretas para mejorar el sistema de generación\n",
        "5. Conclusión: Reflexión final sobre la utilidad y aplicabilidad de los materiales generados\n",
        "\n",
        "Tu informe debe ser objetivo, constructivo y enfocado en el valor educativo de los materiales.\n",
        "\"\"\"\n",
        "\n",
        "        summary_report, _ = gemini_client.generate_content(summary_prompt)\n",
        "\n",
        "        summary_file = eval_dir / \"summary_report.md\"\n",
        "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"# Informe General de Evaluación\\n\\n\")\n",
        "            f.write(summary_report)\n",
        "\n",
        "        all_files.append(summary_file)\n",
        "\n",
        "        # Estadísticas de uso\n",
        "        usage_stats = gemini_client.get_usage_stats()\n",
        "\n",
        "        stats_file = eval_dir / \"usage_statistics.md\"\n",
        "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"# Estadísticas de Uso de API\\n\\n\")\n",
        "            f.write(f\"Total de solicitudes: {usage_stats['total_requests']}\\n\")\n",
        "            f.write(f\"Total de tokens utilizados: {usage_stats['total_tokens_used']}\\n\")\n",
        "            f.write(f\"Costo total estimado: ${usage_stats['total_cost_usd']:.4f}\\n\")\n",
        "            f.write(f\"Modelos utilizados: {', '.join(usage_stats['models_used'])}\\n\")\n",
        "            f.write(f\"Promedio de tokens por solicitud: {usage_stats['average_tokens_per_request']:.2f}\\n\")\n",
        "            f.write(f\"Costo promedio por solicitud: ${usage_stats['average_cost_per_request']:.6f}\\n\")\n",
        "\n",
        "        all_files.append(stats_file)\n",
        "\n",
        "        logger.info(f\"Proceso completado. Se generaron {len(all_files)} archivos.\")\n",
        "        return all_materials, all_evaluations, usage_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error en la generación y evaluación de contenido: {e}\")\n",
        "        import traceback\n",
        "        logger.error(traceback.format_exc())\n",
        "        return None, None, {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "-unABBv5vQJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar el sistema completo\n",
        "\n",
        "# Definir o cargar el contenido del curso\n",
        "course_content = \"\"\"\n",
        "Contenido del curso Cálculo diferencial.\n",
        "Unidades:\n",
        "1. Introducción a la derivada\n",
        "2. Derivada de la función compuesta\n",
        "3. Aplicaciones de la derivada en problemas de razón de cambio\n",
        "\n",
        "Autor: Juan David Ospina Arango\n",
        "Profesor Asociado\n",
        "Departamento de Ciencias de la Computación y de la Decisión\n",
        "Universidad Nacional de Colombia\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutar la generación y evaluación completa\n",
        "all_materials, all_evaluations, usage_stats = generate_and_evaluate_complete_materials(\n",
        "    course_content=course_content,\n",
        "    file_path=\" \",\n",
        "    output_dir=\"output_completo\",\n",
        "    model=\"gemini-2.0-flash-001\",  # Puedes cambiar a otros modelos disponibles\n",
        "    output_format=\"markdown\",  # o \"pdf\" si prefieres PDFs\n",
        "    api_key=api_key  # Asegúrate de tener tu API key definida\n",
        ")\n",
        "\n",
        "# Mostrar resultados\n",
        "if all_materials and all_evaluations:\n",
        "    print(\"\\n¡ÉXITO! Materiales generados y evaluados correctamente\")\n",
        "    print(f\"Total de tipos de materiales: {len(all_materials)}\")\n",
        "    print(f\"Total de unidades procesadas: {len(next(iter(all_materials.values())))}\")\n",
        "    print(f\"Costo total: ${usage_stats['total_cost_usd']:.4f}\")\n",
        "    print(f\"Revisa la carpeta 'output_completo' para ver todos los archivos generados!\")\n",
        "\n",
        "    # Descargar todos los archivos generados\n",
        "    print(\"\\nDescargando archivos generados...\")\n",
        "    !zip -r output_completo.zip output_completo\n",
        "    from google.colab import files\n",
        "    files.download('output_completo.zip')\n",
        "else:\n",
        "    print(\"\\nERROR: No se pudieron generar los materiales.\")\n",
        "    print(\"Detalles del error:\", usage_stats.get(\"error\", \"Error desconocido\"))"
      ],
      "metadata": {
        "id": "F0mbvhpSvXBY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b0c49379-765e-4dc2-ec1e-4e07caff60d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, sube un archivo de curso (PDF, DOCX o TXT):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7160ae9c-de38-4e41-a8bd-e106a2bc0998\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7160ae9c-de38-4e41-a8bd-e106a2bc0998\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 01.01 - Análisis y diseño de algoritmos (2024-2).pdf to 01.01 - Análisis y diseño de algoritmos (2024-2) (2).pdf\n",
            "Archivo 01.01 - Análisis y diseño de algoritmos (2024-2) (2).pdf procesado exitosamente.\n",
            "Modelo Gemini inicializado.   1\n",
            "\n",
            "¡ÉXITO! Materiales generados y evaluados correctamente\n",
            "Total de tipos de materiales: 5\n",
            "Total de unidades procesadas: 3\n",
            "Costo total: $0.0323\n",
            "Revisa la carpeta 'output_completo' para ver todos los archivos generados!\n",
            "\n",
            "Descargando archivos generados...\n",
            "  adding: output_completo/ (stored 0%)\n",
            "  adding: output_completo/discussion_questions/ (stored 0%)\n",
            "  adding: output_completo/discussion_questions/20250307_015611/ (stored 0%)\n",
            "  adding: output_completo/discussion_questions/20250307_015611/: Análisis y Diseño de Algoritmos (3009430)_discussion_questions.md (deflated 70%)\n",
            "  adding: output_completo/discussion_questions/20250307_015611/unit_1_discussion_questions.md (deflated 63%)\n",
            "  adding: output_completo/discussion_questions/20250307_015611/unit_3_discussion_questions.md (deflated 65%)\n",
            "  adding: output_completo/discussion_questions/20250307_015611/unit_2_discussion_questions.md (deflated 64%)\n",
            "  adding: output_completo/discussion_questions/20250307_012728/ (stored 0%)\n",
            "  adding: output_completo/discussion_questions/20250307_012728/: Análisis y Diseño de Algoritmos (3009430)_discussion_questions.md (deflated 71%)\n",
            "  adding: output_completo/discussion_questions/20250307_012728/unit_1_discussion_questions.md (deflated 64%)\n",
            "  adding: output_completo/discussion_questions/20250307_012728/unit_3_discussion_questions.md (deflated 65%)\n",
            "  adding: output_completo/discussion_questions/20250307_012728/unit_2_discussion_questions.md (deflated 66%)\n",
            "  adding: output_completo/evaluations/ (stored 0%)\n",
            "  adding: output_completo/evaluations/exercises_evaluations.md (deflated 68%)\n",
            "  adding: output_completo/evaluations/usage_statistics.md (deflated 33%)\n",
            "  adding: output_completo/evaluations/discussion_questions_evaluations.md (deflated 69%)\n",
            "  adding: output_completo/evaluations/suggested_readings_evaluations.md (deflated 68%)\n",
            "  adding: output_completo/evaluations/class_notes_evaluations.md (deflated 69%)\n",
            "  adding: output_completo/evaluations/summary_report.md (deflated 63%)\n",
            "  adding: output_completo/evaluations/learning_objectives_evaluations.md (deflated 71%)\n",
            "  adding: output_completo/suggested_readings/ (stored 0%)\n",
            "  adding: output_completo/suggested_readings/20250307_013150/ (stored 0%)\n",
            "  adding: output_completo/suggested_readings/20250307_013150/unit_2_suggested_readings.md (deflated 67%)\n",
            "  adding: output_completo/suggested_readings/20250307_013150/: Análisis y Diseño de Algoritmos (3009430)_suggested_readings.md (deflated 75%)\n",
            "  adding: output_completo/suggested_readings/20250307_013150/unit_3_suggested_readings.md (deflated 64%)\n",
            "  adding: output_completo/suggested_readings/20250307_013150/unit_1_suggested_readings.md (deflated 67%)\n",
            "  adding: output_completo/suggested_readings/20250307_020029/ (stored 0%)\n",
            "  adding: output_completo/suggested_readings/20250307_020029/unit_2_suggested_readings.md (deflated 65%)\n",
            "  adding: output_completo/suggested_readings/20250307_020029/: Análisis y Diseño de Algoritmos (3009430)_suggested_readings.md (deflated 77%)\n",
            "  adding: output_completo/suggested_readings/20250307_020029/unit_3_suggested_readings.md (deflated 70%)\n",
            "  adding: output_completo/suggested_readings/20250307_020029/unit_1_suggested_readings.md (deflated 70%)\n",
            "  adding: output_completo/learning_objectives/ (stored 0%)\n",
            "  adding: output_completo/learning_objectives/20250307_012937/ (stored 0%)\n",
            "  adding: output_completo/learning_objectives/20250307_012937/unit_3_learning_objectives.md (deflated 65%)\n",
            "  adding: output_completo/learning_objectives/20250307_012937/: Análisis y Diseño de Algoritmos (3009430)_learning_objectives.md (deflated 73%)\n",
            "  adding: output_completo/learning_objectives/20250307_012937/unit_1_learning_objectives.md (deflated 65%)\n",
            "  adding: output_completo/learning_objectives/20250307_012937/unit_2_learning_objectives.md (deflated 65%)\n",
            "  adding: output_completo/learning_objectives/20250307_015817/ (stored 0%)\n",
            "  adding: output_completo/learning_objectives/20250307_015817/unit_3_learning_objectives.md (deflated 63%)\n",
            "  adding: output_completo/learning_objectives/20250307_015817/: Análisis y Diseño de Algoritmos (3009430)_learning_objectives.md (deflated 73%)\n",
            "  adding: output_completo/learning_objectives/20250307_015817/unit_1_learning_objectives.md (deflated 63%)\n",
            "  adding: output_completo/learning_objectives/20250307_015817/unit_2_learning_objectives.md (deflated 70%)\n",
            "  adding: output_completo/class_notes/ (stored 0%)\n",
            "  adding: output_completo/class_notes/20250307_012318/ (stored 0%)\n",
            "  adding: output_completo/class_notes/20250307_012318/: Análisis y Diseño de Algoritmos (3009430)_class_notes.md (deflated 72%)\n",
            "  adding: output_completo/class_notes/20250307_012318/unit_3_class_notes.md (deflated 66%)\n",
            "  adding: output_completo/class_notes/20250307_012318/unit_1_class_notes.md (deflated 70%)\n",
            "  adding: output_completo/class_notes/20250307_012318/unit_2_class_notes.md (deflated 65%)\n",
            "  adding: output_completo/class_notes/20250307_015106/ (stored 0%)\n",
            "  adding: output_completo/class_notes/20250307_015106/: Análisis y Diseño de Algoritmos (3009430)_class_notes.md (deflated 71%)\n",
            "  adding: output_completo/class_notes/20250307_015106/unit_3_class_notes.md (deflated 67%)\n",
            "  adding: output_completo/class_notes/20250307_015106/unit_1_class_notes.md (deflated 64%)\n",
            "  adding: output_completo/class_notes/20250307_015106/unit_2_class_notes.md (deflated 64%)\n",
            "  adding: output_completo/class_notes/20250307_014621/ (stored 0%)\n",
            "  adding: output_completo/class_notes/20250307_014621/: Análisis y Diseño de Algoritmos (3009430)_class_notes.md (deflated 71%)\n",
            "  adding: output_completo/class_notes/20250307_014621/unit_3_class_notes.md (deflated 64%)\n",
            "  adding: output_completo/class_notes/20250307_014621/unit_1_class_notes.md (deflated 67%)\n",
            "  adding: output_completo/class_notes/20250307_014621/unit_2_class_notes.md (deflated 66%)\n",
            "  adding: output_completo/class_notes/20250307_013250/ (stored 0%)\n",
            "  adding: output_completo/class_notes/20250307_013250/unit_3_class_notes.md (deflated 65%)\n",
            "  adding: output_completo/class_notes/20250307_013250/unit_1_class_notes.md (deflated 63%)\n",
            "  adding: output_completo/class_notes/20250307_013250/unit_2_class_notes.md (deflated 66%)\n",
            "  adding: output_completo/class_notes/20250307_013250/Cálculo diferencial._class_notes.md (deflated 71%)\n",
            "  adding: output_completo/exercises/ (stored 0%)\n",
            "  adding: output_completo/exercises/20250307_015404/ (stored 0%)\n",
            "  adding: output_completo/exercises/20250307_015404/unit_1_exercises.md (deflated 70%)\n",
            "  adding: output_completo/exercises/20250307_015404/unit_3_exercises.md (deflated 69%)\n",
            "  adding: output_completo/exercises/20250307_015404/unit_2_exercises.md (deflated 71%)\n",
            "  adding: output_completo/exercises/20250307_015404/: Análisis y Diseño de Algoritmos (3009430)_exercises.md (deflated 73%)\n",
            "  adding: output_completo/exercises/20250307_013515/ (stored 0%)\n",
            "  adding: output_completo/exercises/20250307_013515/unit_1_exercises.md (deflated 68%)\n",
            "  adding: output_completo/exercises/20250307_013515/Cálculo diferencial._exercises.md (deflated 72%)\n",
            "  adding: output_completo/exercises/20250307_013515/unit_3_exercises.md (deflated 69%)\n",
            "  adding: output_completo/exercises/20250307_013515/unit_2_exercises.md (deflated 69%)\n",
            "  adding: output_completo/exercises/20250307_014923/ (stored 0%)\n",
            "  adding: output_completo/exercises/20250307_014923/unit_1_exercises.md (deflated 69%)\n",
            "  adding: output_completo/exercises/20250307_014923/unit_3_exercises.md (deflated 68%)\n",
            "  adding: output_completo/exercises/20250307_014923/unit_2_exercises.md (deflated 70%)\n",
            "  adding: output_completo/exercises/20250307_014923/: Análisis y Diseño de Algoritmos (3009430)_exercises.md (deflated 73%)\n",
            "  adding: output_completo/exercises/20250307_012538/ (stored 0%)\n",
            "  adding: output_completo/exercises/20250307_012538/unit_1_exercises.md (deflated 69%)\n",
            "  adding: output_completo/exercises/20250307_012538/unit_3_exercises.md (deflated 66%)\n",
            "  adding: output_completo/exercises/20250307_012538/unit_2_exercises.md (deflated 68%)\n",
            "  adding: output_completo/exercises/20250307_012538/: Análisis y Diseño de Algoritmos (3009430)_exercises.md (deflated 71%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d174a2b-bc90-4b32-ae4c-e1c8e6e48445\", \"output_completo.zip\", 272402)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}